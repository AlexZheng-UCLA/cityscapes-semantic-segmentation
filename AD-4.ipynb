{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c62b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac10f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if want to run by CPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70dcb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train = h5py.File('C:/Users/AlexZheng/Downloads/train.h5', 'r')   \n",
    "f_test = h5py.File('C:/Users/AlexZheng/Downloads/test.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975e80f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_train = np.array(f_train['rgb'])               \n",
    "seg_train = np.array(f_train['seg'])\n",
    "color_codes = np.array(f_train['color_codes'])\n",
    "\n",
    "rgb_test = np.array(f_test['rgb'])\n",
    "seg_test = np.array(f_test['seg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ee5b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input,Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate, BatchNormalization\n",
    "\n",
    "\n",
    "filters = 16\n",
    "Dropout_rate = 0.2\n",
    "\n",
    "def Conv_Block(filters, input):\n",
    "    conv = Conv2D(filters=filters, kernel_size=(3,3), padding='same', activation= 'relu')(input)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = Conv2D(filters=filters, kernel_size=(3,3), padding='same', activation= 'relu')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    pool = MaxPooling2D(pool_size=(2,2))(conv)\n",
    "    pool = Dropout(Dropout_rate)(pool, training=True)\n",
    "    \n",
    "    return conv,pool\n",
    "\n",
    "def Deconv_Block(filters, conv, input):\n",
    "    deconv = Conv2DTranspose(filters=8*filters, kernel_size=(3,3), padding='same',  strides=(2,2))(input)\n",
    "    deconv = BatchNormalization()(deconv)\n",
    "    conca = concatenate([deconv, conv])\n",
    "    conca = Dropout(Dropout_rate)(conca)\n",
    "    conca = Conv2D(filters=8*filters, kernel_size=(3,3), padding='same', activation= 'relu')(conca)\n",
    "    conca = BatchNormalization()(conca)\n",
    "    conca = Conv2D(filters=8*filters, kernel_size=(3,3), padding='same', activation= 'relu')(conca)\n",
    "    conca = BatchNormalization()(conca)\n",
    "    conca = Dropout(Dropout_rate)(conca, training=True)\n",
    "    \n",
    "    return conca \n",
    "\n",
    "# Input \n",
    "input = Input((128,256,3))\n",
    "\n",
    "# Conv part \n",
    "conv1, pool1 = Conv_Block(filters, input)\n",
    "conv2, pool2 = Conv_Block(2*filters, pool1)\n",
    "conv3, pool3 = Conv_Block(4*filters, pool2)\n",
    "conv4, pool4 = Conv_Block(8*filters, pool3)\n",
    "conv5, pool5 = Conv_Block(16*filters, pool4)\n",
    "\n",
    "# Middle part \n",
    "conv = Conv2D(filters=32*filters, kernel_size=(3,3), padding='same', activation= 'relu')(pool5)\n",
    "conv = BatchNormalization()(conv)\n",
    "conv = Conv2D(filters=32*filters, kernel_size=(3,3), padding='same', activation= 'relu')(conv)\n",
    "conv = BatchNormalization()(conv)\n",
    "conv = Dropout(Dropout_rate)(conv, training=True)\n",
    "\n",
    "# Deconv part \n",
    "conca5 = Deconv_Block(16*filters, conv5, conv)\n",
    "conca4 = Deconv_Block(8*filters, conv4, conca5)\n",
    "conca3 = Deconv_Block(4*filters, conv3, conca4)\n",
    "conca2 = Deconv_Block(2*filters, conv2, conca3)\n",
    "conca1 = Deconv_Block(filters, conv1, conca2)\n",
    "\n",
    "# Output \n",
    "output = Conv2D(filters=34, kernel_size=(1,1), activation='softmax')(conca1)\n",
    "\n",
    "model1 = tf.keras.Model(inputs = input, outputs = output)\n",
    "model1.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1851ee3d",
   "metadata": {},
   "source": [
    "# Unet\n",
    "\n",
    "## Input \n",
    "input = Input((128,256,3))\n",
    "    \n",
    "## Conv part \n",
    "conv1 = Conv2D(filters=filters, kernel_size=(3,3), padding='same', activation= 'relu')(input)\n",
    "conv1 = BatchNormalization(conv1)\n",
    "conv1 = Conv2D(filters=filters, kernel_size=(3,3), padding='same', activation= 'relu')(conv1)\n",
    "conv1 = BatchNormalization(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "pool1 = Dropout(Dropout_rate)(pool1)\n",
    "\n",
    "conv2 = Conv2D(filters=2*filters, kernel_size=(3,3), padding='same', activation= 'relu')(pool1)\n",
    "conv2 = BatchNormalization(conv2)\n",
    "conv2 = Conv2D(filters=2*filters, kernel_size=(3,3), padding='same', activation= 'relu')(conv2)\n",
    "conv2 = BatchNormalization(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "pool2 = Dropout(Dropout_rate)(pool2)\n",
    "\n",
    "conv3 = Conv2D(filters=4*filters, kernel_size=(3,3), padding='same', activation= 'relu')(pool2)\n",
    "conv3 = BatchNormalization(conv3)\n",
    "conv3 = Conv2D(filters=4*filters, kernel_size=(3,3), padding='same', activation= 'relu')(conv3)\n",
    "conv3 = BatchNormalization(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "pool3 = Dropout(Dropout_rate)(pool3)\n",
    "\n",
    "conv4 = Conv2D(filters=8*filters, kernel_size=(3,3), padding='same', activation= 'relu')(pool3)\n",
    "conv4 = BatchNormalization(conv4)\n",
    "conv4 = Conv2D(filters=8*filters, kernel_size=(3,3), padding='same', activation= 'relu')(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2,2))(conv4)\n",
    "pool4 = Dropout(Dropout_rate)(pool4)\n",
    "\n",
    "conv5 = Conv2D(filters=16*filters, kernel_size=(3,3), padding='same', activation= 'relu')(pool4)\n",
    "conv5 = BatchNormalization(conv5)\n",
    "conv5 = Conv2D(filters=16*filters, kernel_size=(3,3), padding='same', activation= 'relu')(conv5)\n",
    "conv5 = BatchNormalization(conv5)\n",
    "pool5 = MaxPooling2D(pool_size=(2,2))(conv5)\n",
    "pool5 = Dropout(Dropout_rate)(pool5)\n",
    "\n",
    "## Middle part \n",
    "conv = Conv2D(filters=32*filters, kernel_size=(3,3), padding='same', activation= 'relu')(pool5)\n",
    "conv = BatchNormalization(conv)\n",
    "conv = Conv2D(filters=32*filters, kernel_size=(3,3), padding='same', activation= 'relu')(conv)\n",
    "conv = BatchNormalization(conv)\n",
    "\n",
    "## Deconv part \n",
    "deconv5 = Conv2DTranspose(filters=16*filters, kernel_size=(3,3), padding='same', strides=(2,2))(conv)\n",
    "conca5 = concatenate([deconv5, conv5])\n",
    "conca5 = Dropout(Dropout_rate)(conca5)\n",
    "conca5 = Conv2D(filters=16*filters, kernel_size=(3,3), padding='same', activation= 'relu')(conca5)\n",
    "conca5 = Conv2D(filters=16*filters, kernel_size=(3,3), padding='same', activation= 'relu')(conca5)\n",
    "\n",
    "deconv4 = Conv2DTranspose(filters=8*filters, kernel_size=(3,3), padding='same',  strides=(2,2))(conca5)\n",
    "conca4 = concatenate([deconv4, conv4])\n",
    "conca4 = Dropout(Dropout_rate)(conca4)\n",
    "conca4 = Conv2D(filters=8*filters, kernel_size=(3,3), padding='same', activation= 'relu')(conca4)\n",
    "conca4 = Conv2D(filters=8*filters, kernel_size=(3,3), padding='same', activation= 'relu')(conca4)\n",
    "\n",
    "deconv3 = Conv2DTranspose(filters=4*filters, kernel_size=(3,3), padding='same',  strides=(2,2))(conca4)\n",
    "conca3 = concatenate([deconv3, conv3])\n",
    "conca3 = Dropout(Dropout_rate)(conca3)\n",
    "conca3 = Conv2D(filters=4*filters, kernel_size=(3,3), padding='same', activation= 'relu')(conca3)\n",
    "conca3= Conv2D(filters=4*filters, kernel_size=(3,3), padding='same', activation= 'relu')(conca3)\n",
    "\n",
    "deconv2 = Conv2DTranspose(filters=2*filters, kernel_size=(3,3), padding='same',  strides=(2,2))(conca3)\n",
    "conca2 = concatenate([deconv2, conv2])\n",
    "conca2 = Dropout(Dropout_rate)(conca2)\n",
    "conca2 = Conv2D(filters=2*filters, kernel_size=(3,3), padding='same', activation= 'relu')(conca2)\n",
    "conca2 = Conv2D(filters=2*filters, kernel_size=(3,3), padding='same', activation= 'relu')(conca2)\n",
    "\n",
    "deconv1 = Conv2DTranspose(filters=filters, kernel_size=(3,3), padding='same',  strides=(2,2))(conca2)\n",
    "conca1 = concatenate([deconv1, conv1])\n",
    "conca1 = Dropout(Dropout_rate)(conca1)\n",
    "conca1 = Conv2D(filters=filters, kernel_size=(3,3), padding='same', activation= 'relu')(conca1)\n",
    "conca1 = Conv2D(filters=filters, kernel_size=(3,3), padding='same', activation= 'relu')(conca1)\n",
    "\n",
    "##  Output\n",
    "output = Conv2D(filters=34, kernel_size=(1,1), activation='softmax')(conca1)\n",
    "\n",
    "model1 = tf.keras.Model(inputs = input, outputs = output)\n",
    "model1.summary() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20c5d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model1)    # plot the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df9d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks  \n",
    "\n",
    "model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model1.optimizer.lr = 1E-3\n",
    "\n",
    "log_dir = \"logs/fit/Unet\"\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)        \n",
    "\n",
    "#with tf.device(\"/CPU:0\"):\n",
    "model1.history = model1.fit(\n",
    "    x = rgb_train, \n",
    "    y = seg_train,\n",
    "    batch_size=16,                      # reduce the batch_size to save storage \n",
    "    epochs=50,                          # reduce the epoches to shorten the training time \n",
    "    validation_data=(rgb_test, seg_test),\n",
    "    callbacks=[tensorboard_callback]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('models/model1.h5')        # save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf415e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.load_model('models/model4.h5')   # load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87d95ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model1.predict(rgb_test[:20])          # get 20 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42152de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output2img(data):                                # onehot code to imgs\n",
    "    imgs = np.zeros((data.shape[0],data.shape[1],data.shape[2],3))\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            for k in range(data.shape[2]):\n",
    "                label = np.argmax(data[i,j,k,:])\n",
    "                imgs[i,j,k] = np.array(color_codes[label])\n",
    "    return imgs\n",
    "\n",
    "def seg2img(data):                                  # seg label to imgs \n",
    "    \n",
    "    imgs = np.zeros((data.shape[0],data.shape[1],data.shape[2],3)) \n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            for k in range(data.shape[2]):\n",
    "                imgs[i,j,k] = np.array(color_codes[data[i,j,k]])\n",
    "    return imgs\n",
    "\n",
    "imgs_pred = output2img(predictions)\n",
    "imgs_true = seg2img(seg_test[:20])\n",
    "imgs_orig = rgb_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57f3809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the images \n",
    "plt.figure(figsize=(12, 24))\n",
    "num = 3\n",
    "k = 9\n",
    "plt.title(\"Image Comparations\")\n",
    "\n",
    "for i in range(num):\n",
    "    plt.subplot(num, 3, i*num+1)\n",
    "    plt.title(\"Original Image \"+str(i+4))\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(imgs_orig[i+k]))\n",
    "    plt.subplot(num, 3, i*num+2)\n",
    "    plt.title(\"Image True Seg \"+str(i+4))\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(imgs_true[i+k]))\n",
    "    plt.subplot(num, 3, i*num+3)\n",
    "    plt.title(\"Model Output \"+str(i+4))\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(imgs_pred[i+k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfc017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aleatoric and epistemic uncertainties\n",
    "\n",
    "def alea_uncertainties(predict, true):\n",
    "    img_alea = np.zeros((128, 256))\n",
    "    for i in range(128):\n",
    "        for j in range(256):\n",
    "            uncertainty = -np.log(predict[i,j,true[i,j]])\n",
    "            img_alea[i,j] = uncertainty\n",
    "    seaborn.heatmap(img_alea)\n",
    "    \n",
    "def epis_uncertainties(predict):\n",
    "    img_epis = np.zeros((128, 256))\n",
    "    num = predict.shape[0]\n",
    "    for i in range(128):\n",
    "        for j in range(256):\n",
    "            list = []\n",
    "            for k in range(num): \n",
    "                label = np.argmax(predict[k,i,j,:])\n",
    "                list.append(label)\n",
    "            uncertainty = np.var(list)\n",
    "            img_epis[i,j] = uncertainty\n",
    "    seaborn.heatmap(img_epis, )\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43d7b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.title(\"Uncertainties\")\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"aleatoric uncertainty 5\")\n",
    "alea_uncertainties(predictions[10], seg_test[10])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"epistemic uncertainty 5\")\n",
    "epis_uncertainties(predict_list5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01bdac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
